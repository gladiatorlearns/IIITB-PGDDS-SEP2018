Cluster Tendency

Before we apply any clustering algorithm to the given data, it's important to check whether the given data has some meaningful clusters or not? which in general means the given data is not random. The process to evaluate the data to check if the data is feasible for clustering or not is know as the clustering tendency.

 

As we have already discussed in the previous lecture that the clustering algorithm will return K clusters even if that data does not have any clusters or have any meaningful clusters. So before proceeding for clustering, we should not blindly apply the clustering method and we should check the clustering tendency.

To check cluster tendency, we use Hopkins test. Hopkins test examines whether data points differ significantly from uniformly distributed data in the multidimensional space.

 
Additional Resources

To read about Hopkins test in detail, please follow this link1, link2, remember that the document is described using R programming, please ignore it.
 
 https://www.datanovia.com/en/lessons/assessing-clustering-tendency/#methods-for-assessing-clustering-tendency
 
 https://stats.stackexchange.com/questions/332651/validating-cluster-tendency-using-hopkins-statistic
 
 
 Statistical methods

The Hopkins statistic (Lawson and Jurs 1990) is used to assess the clustering tendency of a data set by measuring the probability that a given data set is generated by a uniform data distribution. In other words, it tests the spatial randomness of the data.

For example, let D be a real data set. The Hopkins statistic can be calculated as follow:

    Sample uniformly n

points (p1,…, pn
) from D.
Compute the distance, xi
, from each real point to each nearest neighbor: For each point pi∈D, find it’s nearest neighbor pj; then compute the distance between pi and pj and denote it as xi=dist(pi,pj)
Generate a simulated data set (randomD
) drawn from a random uniform distribution with n points (q1,…, qn
) and the same variation as the original real data set D.
Compute the distance, yi
from each artificial point to the nearest real data point: For each point qi∈randomD, find it’s nearest neighbor qj in D; then compute the distance between qi and qj and denote it yi=dist(qi,qj)

    Calculate the Hopkins statistic (H) as the mean nearest neighbor distance in the random data set divided by the sum of the mean nearest neighbor distances in the real and across the simulated data set.

The formula is defined as follow:

H=∑i=1nyi∑i=1nxi+∑i=1nyi

How to interpret the Hopkins statistics? If D
were uniformly distributed, then ∑i=1nyi and ∑i=1nxi would be close to each other, and thus H would be about 0.5. However, if clusters are present in D, then the distances for artificial points (∑i=1nyi) would be substantially larger than for the real ones (∑i=1nxi) in expectation, and thus the value of H

will increase (Han, Kamber, and Pei 2012).

A value for H

higher than 0.75 indicates a clustering tendency at the 90% confidence level.

The null and the alternative hypotheses are defined as follow:

    Null hypothesis: the data set D is uniformly distributed (i.e., no meaningful clusters)
    Alternative hypothesis: the data set D is not uniformly distributed (i.e., contains meaningful clusters)

We can conduct the Hopkins Statistic test iteratively, using 0.5 as the threshold to reject the alternative hypothesis. That is, if H < 0.5, then it is unlikely that D has statistically significant clusters.

Put in other words, If the value of Hopkins statistic is close to 1, then we can reject the null hypothesis and conclude that the dataset D is significantly a clusterable data.
